[
  {
    "objectID": "corporate.html",
    "href": "corporate.html",
    "title": "Corporate Story",
    "section": "",
    "text": "As we’re doing for the nonprofit sector, we’ll put together a summary of the important metrics and statistics we think should be included in our dashboard, based on our analysis of SEC data from the corporate sector.\nThis will include both the data itself and some options for visualizing it.\nWe’re working with two main SEC datasets:\n\nNumeric data (num.csv)—this includes information from the Balance Sheet, Income Statement, Cash Flows, Changes in Equity, and Comprehensive Income, plus any related footnotes.\nSubmission data (sub.csv)—this contains text fields like company names, business addresses, and submission detail level.\n\nFor a deeper dive into these datasets and links to access them directly, check out this page: https://theundivideproject.github.io/Financial-Data-Exploration/website/index.html\n                    \n\nLooking to replicate this? Here is the code we used to process the raw SEC data before importing it into Tableau for the visualizations above.:\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# prevent truncation of data\npd.set_option('display.max_rows', None)\npd.set_option('display.max_colwidth', None)\n\n# data for jan (01) — nov (11) 2024 is downloaded from 'https://www.sec.gov/data-research/financial-statement-notes-data-sets'\n\n# load submission data\nsubs = [\n    pd.read_csv(f'financial statement and notes data sets (2024)/{str(i).zfill(2)}/sub.tsv', sep='\\t', low_memory=False) \n    for i in range(1, 11)\n]\n\n# load tag data\ntags = [\n    pd.read_csv(f'financial statement and notes data sets (2024)/{str(i).zfill(2)}/tag.tsv', sep='\\t', low_memory=False) \n    for i in range(1, 11)\n]\n\n# load numeric data\nnums = [\n    pd.read_csv(f'financial statement and notes data sets (2024)/{str(i).zfill(2)}/num.tsv', sep='\\t', low_memory=False) \n    for i in range(1, 11)\n]\n\n# load textual data\ntxts = [\n    pd.read_csv(f'financial statement and notes data sets (2024)/{str(i).zfill(2)}/txt.tsv', sep='\\t', low_memory=False) \n    for i in range(1, 11)\n]\n\n# concatenate data\nsub_2024 = pd.concat(subs, axis=0)\ntag_2024 = pd.concat(tags, axis=0)\nnum_2024 = pd.concat(nums, axis=0)\ntxt_2024 = pd.concat(txts, axis=0)\n\n# drop international data\nsub_2024 = sub_2024[sub_2024['countryba'] == 'US']\nnum_2024 = num_2024[num_2024['adsh'].isin(sub_2024['adsh'])]\ntxt_2024 = txt_2024[txt_2024['adsh'].isin(sub_2024['adsh'])]\n\n# drop duplicate data\nsub_2024 = sub_2024.drop_duplicates(subset='adsh', keep='last')\ntag_2024 = tag_2024.drop_duplicates(subset='tag', keep='last')\nnum_2024 = num_2024.drop_duplicates()\ntxt_2024 = txt_2024.drop_duplicates()\n\n# drop abstract tags\ntag_2024 = tag_2024[tag_2024['abstract'] == 0]\n\n# sum values for entries w/ the same issuer and tag\nnum_2024 = num_2024.groupby(['adsh', 'tag'], as_index=False)['value'].sum()\n\n# EJ-related numeric tags, identified from manual search of tag_2024['tag']\nnum_tags = ['PaymentsForEnvironmentalLiabilities', 'LiabilityForAsbestosAndEnvironmentalClaimsGrossPaymentForClaims',\n'AccrualForEnvironmentalLossContingencies', 'AmountCommittedForFundingSocialAndInfrastructureImprovementProjects', \n'CharitableContributions', 'Revenues']\n\n# show stats for each EJ-related numeric tag\nfor num_tag in num_tags:\n    print(num_tag)\n    display(num_2024[num_2024['tag'] == num_tag].describe())\n    \n# merge data corresponding to num_tags w/ submission data and save as csv\ndata = num_2024[num_2024['tag'].isin(num_tags)].merge(sub_2024, on='adsh', how='left')\ndata.to_csv('data.csv', index=False)"
  }
]